schema: hugoblox/author/v1
slug: me
is_owner: true
name:
  display: Gagan Bhatia
  given: Gagan
  family: Bhatia
  alternate: ''
  pronunciation: ''
  pronouns: he/him
postnominals:
  - MSc
status:
  icon: "ðŸ¤–"
role: AI Research Scientist
bio: |
  Gagan Bhatia is an AI Research Scientist specializing in Large Language Models,
  Natural Language Processing, and Multimodal AI. His research has been published
  in top-tier conferences including EMNLP, NAACL, and ACL, focusing on temporal
  reasoning in LLMs, multilingual AI systems, and Arabic NLP.

affiliations:
  - name: University of Aberdeen
    url: https://www.abdn.ac.uk/

links:
  - icon: at-symbol
    url: mailto:gbhatia880@gmail.com
    label: E-mail Me
  - icon: brands/github
    url: https://github.com/gagan3012
  - icon: brands/linkedin
    url: https://www.linkedin.com/in/gaganbhatiaml
  - icon: academicons/google-scholar
    url: https://scholar.google.com/citations?user=2Z0KWkEAAAAJ&hl=en

interests:
  - Large Language Models
  - Natural Language Processing
  - Multimodal AI
  - Temporal Reasoning
  - Arabic NLP
  - LLM Fine-Tuning

education:
  - degree: MSc. Artificial Intelligence
    institution: University of Aberdeen
    start: 2024-09-01
    end: 2025-08-31
    summary: |
      Thesis: Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models
  - degree: BASc. Electrical and Computer Engineering
    institution: University of British Columbia
    start: 2018-09-01
    end: 2023-05-31

experience:
  - role: Research Assistant
    org: University of Aberdeen
    start: 2025-03-01
    end: 2025-10-31
    summary: |
      Designed and built a Python-based framework using PyTorch to systematically evaluate temporal reasoning failures in LLMs, identifying date tokenisation as a primary bottleneck. Implemented attention-based interpretability methods and designed Agentic AI frameworks for data extraction.
  - role: Research Assistant
    org: University of British Columbia
    start: 2022-09-01
    end: 2024-09-30
    summary: |
      Engineered and trained a foundation model (Qalam) for Arabic OCR, achieving a 3-point F1 score improvement over SOTA. Built and benchmarked multimodal LLMs (FinTral) using distributed training. Developed PolyDeDupe, a Python package that improved multilingual data cleaning pipelines by 40%.
  - role: Machine Learning Engineer
    org: Xtract One
    start: 2021-10-01
    end: 2022-09-30
    summary: |
      Owned the full lifecycle of a Vision Transformer (ViT) system for image manipulation detection, from training to deployment via REST API on AWS for a national defense client. Architected and deployed a scalable document intelligence pipeline on AWS.
  - role: Software Engineer
    org: Amazon Web Services
    start: 2021-05-01
    end: 2021-12-31
    summary: |
      Enhanced the core NLU model for AWS Lex, improving intent recognition accuracy by 10%. Deployed a production-ready XGBoost model on AWS SageMaker for healthcare applications.

skills:
  - name: Languages
    items:
      - label: Python
        level: 5
      - label: C++
        level: 4
      - label: Java
        level: 4
      - label: SQL
        level: 4
      - label: Go
        level: 3
      - label: Swift
        level: 3
  - name: AI/ML Frameworks
    items:
      - label: PyTorch
        level: 5
      - label: TensorFlow
        level: 4
      - label: JAX
        level: 4
      - label: Hugging Face
        level: 5
      - label: Scikit-learn
        level: 4
      - label: LangChain
        level: 4
  - name: Tools & Platforms
    items:
      - label: AWS
        level: 5
      - label: GCP
        level: 4
      - label: Docker
        level: 4
      - label: Kubernetes
        level: 3
      - label: Git
        level: 5

languages:
  - name: English
    level: 5
    label: Native

awards:
  - title: Published 9+ papers in top-tier conferences
    awarder: ACL, NAACL, EMNLP, ArabicNLP
    date: "2024-07-01"
    summary: Research contributions in LLMs, temporal reasoning, and Arabic NLP.
    icon: hero/trophy
