---
title: 'Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning'

authors:
  - me
  - Maxime Peyrard
  - Wei Zhao

date: '2025-11-01T00:00:00Z'
publishDate: '2025-05-16T00:00:00Z'

publication_types: ['paper-conference']

publication: In *Empirical Methods in Natural Language Processing (EMNLP 2025)*
publication_short: In *EMNLP 2025*

abstract: This paper identifies date tokenization as a primary bottleneck in temporal reasoning for Large Language Models. Through systematic evaluation using PyTorch-based frameworks, we demonstrate how date fragmentation during tokenization significantly impacts LLM performance on temporal tasks.

summary: Identifies date tokenization as a critical bottleneck affecting temporal reasoning in Large Language Models.

tags:
  - Large Language Models
  - Temporal Reasoning
  - Tokenization

featured: true

hugoblox:
  ids:
    doi: ''

links:
  - type: pdf
    url: "https://arxiv.org/abs/2505.16088"
  - type: source
    url: "https://arxiv.org/abs/2505.16088"

image:
  caption: ''
  focal_point: ''
  preview_only: false

projects: []
slides: ""
---

This research introduces comprehensive analysis of how modern tokenizers fragment dates, leading to systematic failures in temporal reasoning tasks. We provide actionable insights for improving LLM architecture and training approaches.
