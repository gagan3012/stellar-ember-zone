"@article{bhatia2024fintral,
Author        = {Gagan Bhatia and El Moatez Billah Nagoudi and Hasan Cavusoglu and Muhammad Abdul-Mageed},
Title         = {FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models},
Journal       = {2402.10986v3},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {We introduce FinTral, a suite of state-of-the-art multimodal large language models (LLMs) built upon the Mistral-7b model and tailored for financial analysis. FinTral integrates textual, numerical, tabular, and image data. We enhance FinTral with domain-specific pretraining, instruction fine-tuning, and RLAIF training by exploiting a large collection of textual and visual datasets we curate for this work. We also introduce an extensive benchmark featuring nine tasks and 25 datasets for evaluation, including hallucinations in the financial domain. Our FinTral model trained with direct preference optimization employing advanced Tools and Retrieval methods, dubbed FinTral-DPO-T&R, demonstrates an exceptional zero-shot performance. It outperforms ChatGPT-3.5 in all tasks and surpasses GPT-4 in five out of nine tasks, marking a significant advancement in AI-driven financial technology. We also demonstrate that FinTral has the potential to excel in real-time analysis and decision-making in diverse financial contexts. The GitHub repository for FinTral is available at \url{https://github.com/UBC-NLP/fintral}.},
Year          = {2024},
Month         = {Feb},
Url           = {http://arxiv.org/abs/2402.10986v3},
File          = {2402.10986v3.pdf}
}"
"@article{kwon2023chatgpt,
Author        = {Sang Yun Kwon and Gagan Bhatia and El Moatez Billah Nagoud and Muhammad Abdul-Mageed},
Title         = {ChatGPT for Arabic Grammatical Error Correction},
Journal       = {2308.04492v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.AI},
Abstract      = {Recently, large language models (LLMs) fine-tuned to follow human instruction have exhibited significant capabilities in various English NLP tasks. However, their performance in grammatical error correction (GEC) tasks, particularly in non-English languages, remains significantly unexplored. In this paper, we delve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task made complex due to Arabic's rich morphology. Our findings suggest that various prompting methods, coupled with (in-context) few-shot learning, demonstrate considerable effectiveness, with GPT-4 achieving up to $65.49$ F\textsubscript{1} score under expert prompting (approximately $5$ points higher than our established baseline). This highlights the potential of LLMs in low-resource settings, offering a viable approach for generating useful synthetic data for model training. Despite these positive results, we find that instruction fine-tuned models, regardless of their size, significantly underperform compared to fully fine-tuned models of significantly smaller sizes. This disparity highlights a substantial room for improvements for LLMs. Inspired by methods from low-resource machine translation, we also develop a method exploiting synthetic data that significantly outperforms previous models on two standard Arabic benchmarks. Our work sets new SoTA for Arabic GEC, with $72.19\%$ and $73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively.},
Year          = {2023},
Month         = {Aug},
Url           = {http://arxiv.org/abs/2308.04492v1},
File          = {2308.04492v1.pdf}
}"
"@article{alwajih2024peacock,
Author        = {Fakhraddin Alwajih and El Moatez Billah Nagoudi and Gagan Bhatia and Abdelrahman Mohamed and Muhammad Abdul-Mageed},
Title         = {Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks},
Journal       = {2403.01031v2},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic culture, setting the first stone for culturally-aware Arabic MLLMs.The GitHub repository for the \textit{Peacock} project is available at \url{https://github.com/UBC-NLP/peacock}.},
Year          = {2024},
Month         = {Mar},
Url           = {http://arxiv.org/abs/2403.01031v2},
File          = {2403.01031v2.pdf}
}"
"@article{alwajih2024dallah,
Author        = {Fakhraddin Alwajih and Gagan Bhatia and Muhammad Abdul-Mageed},
Title         = {Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic},
Journal       = {2407.18129v2},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Recent advancements have significantly enhanced the capabilities of Multimodal Large Language Models (MLLMs) in generating and understanding image-to-text content. Despite these successes, progress is predominantly limited to English due to the scarcity of high quality multimodal resources in other languages. This limitation impedes the development of competitive models in languages such as Arabic. To alleviate this situation, we introduce an efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced language model based on LLaMA-2 to facilitate multimodal interactions. Dallah demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning six Arabic dialects, Dallah showcases its capability to handle complex dialectal interactions incorporating both textual and visual elements. The model excels in two benchmark tests: one evaluating its performance on Modern Standard Arabic (MSA) and another specifically designed to assess dialectal responses. Beyond its robust performance in multimodal interaction tasks, Dallah has the potential to pave the way for further development of dialect-aware Arabic MLLMs.},
Year          = {2024},
Month         = {Jul},
Url           = {http://arxiv.org/abs/2407.18129v2},
File          = {2407.18129v2.pdf}
}"
"@article{bhatia2024qalam,
Author        = {Gagan Bhatia and El Moatez Billah Nagoudi and Fakhraddin Alwajih and Muhammad Abdul-Mageed},
Title         = {Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting Recognition},
Journal       = {2407.13559v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CV},
Abstract      = {Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR) pose unique challenges due to the cursive and context-sensitive nature of the Arabic script. This study introduces Qalam, a novel foundation model designed for Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder architecture. Our model significantly outperforms existing methods, achieving a Word Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We train Qalam on a diverse dataset, including over 4.5 million images from Arabic manuscripts and a synthetic dataset comprising 60k image-text pairs. Notably, Qalam demonstrates exceptional handling of Arabic diacritics, a critical feature in Arabic scripts. Furthermore, it shows a remarkable ability to process high-resolution inputs, addressing a common limitation in current OCR systems. These advancements underscore Qalam's potential as a leading solution for Arabic script recognition, offering a significant leap in accuracy and efficiency.},
Year          = {2024},
Month         = {Jul},
Url           = {http://arxiv.org/abs/2407.13559v1},
File          = {2407.13559v1.pdf}
}"
"@article{bhatia2024swan,
Author        = {Gagan Bhatia and El Moatez Billah Nagoudi and Abdellah El Mekki and Fakhraddin Alwajih and Muhammad Abdul-Mageed},
Title         = {Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks},
Journal       = {2411.01192v3},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {We introduce {\bf Swan}, a family of embedding models centred around the Arabic language, addressing both small-scale and large-scale use cases. Swan includes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on ArMistral, a pretrained Arabic large language model. To evaluate these models, we propose ArabicMTEB, a comprehensive benchmark suite that assesses cross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text embedding performance, covering eight diverse tasks and spanning 94 datasets. Swan-Large achieves state-of-the-art results, outperforming Multilingual-E5-large in most Arabic tasks, while the Swan-Small consistently surpasses Multilingual-E5-base. Our extensive evaluations demonstrate that Swan models are both dialectally and culturally aware, excelling across various Arabic domains while offering significant monetary efficiency. This work significantly advances the field of Arabic language modelling and provides valuable resources for future research and applications in Arabic natural language processing. Our models and benchmark are available at our GitHub page: \href{https://github.com/UBC-NLP/swan}{https://github.com/UBC-NLP/swan}},
Year          = {2024},
Month         = {Nov},
Url           = {http://arxiv.org/abs/2411.01192v3},
File          = {2411.01192v3.pdf}
}"
"@article{kwon2023zero-shot,
Author        = {Sang Yun Kwon and Gagan Bhatia and El Moatez Billah Nagoudi and Alcides Alcoba Inciarte and Muhammad Abdul-Mageed},
Title         = {Zero-Shot Slot and Intent Detection in Low-Resource Languages},
Journal       = {2304.13292v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Intent detection and slot filling are critical tasks in spoken and natural language understanding for task-oriented dialog systems. In this work we describe our participation in the slot and intent detection for low-resource language varieties (SID4LR; Aepli et al. (2023)). We investigate the slot and intent detection (SID) tasks using a wide range of models and settings. Given the recent success of multitask-prompted finetuning of large language models, we also test the generalization capability of the recent encoder-decoder model mT0 (Muennighoff et al., 2022) on new tasks (i.e., SID) in languages they have never intentionally seen. We show that our best model outperforms the baseline by a large margin (up to +30 F1 points) in both SID tasks},
Year          = {2023},
Month         = {Apr},
Url           = {http://arxiv.org/abs/2304.13292v1},
File          = {2304.13292v1.pdf}
}"
"@article{bhatia2023ubc-dlnlp,
Author        = {Gagan Bhatia and Ife Adebara and AbdelRahim Elmadany and Muhammad Abdul-Mageed},
Title         = {UBC-DLNLP at SemEval-2023 Task 12: Impact of Transfer Learning on African Sentiment Analysis},
Journal       = {2304.11256v2},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {We describe our contribution to the SemEVAl 2023 AfriSenti-SemEval shared task, where we tackle the task of sentiment analysis in 14 different African languages. We develop both monolingual and multilingual models under a full supervised setting (subtasks A and B). We also develop models for the zero-shot setting (subtask C). Our approach involves experimenting with transfer learning using six language models, including further pertaining of some of these models as well as a final finetuning stage. Our best performing models achieve an F1-score of 70.36 on development data and an F1-score of 66.13 on test data. Unsurprisingly, our results demonstrate the effectiveness of transfer learning and fine-tuning techniques for sentiment analysis across multiple languages. Our approach can be applied to other sentiment analysis tasks in different languages and domains.},
Year          = {2023},
Month         = {Apr},
Url           = {http://arxiv.org/abs/2304.11256v2},
File          = {2304.11256v2.pdf}
}"
"@article{mahanta2025leveraging,
Author        = {Cristina Mahanta and Gagan Bhatia},
Title         = {Leveraging Vision-Language Pre-training for Human Activity Recognition in Still Images},
Journal       = {2506.13458v1},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CV},
Abstract      = {Recognising human activity in a single photo enables indexing, safety and assistive applications, yet lacks motion cues. Using 285 MSCOCO images labelled as walking, running, sitting, and standing, scratch CNNs scored 41% accuracy. Fine-tuning multimodal CLIP raised this to 76%, demonstrating that contrastive vision-language pre-training decisively improves still-image action recognition in real-world deployments.},
Year          = {2025},
Month         = {Jun},
Url           = {http://arxiv.org/abs/2506.13458v1},
File          = {2506.13458v1.pdf}
}"
"@article{bhatia2025date,
Author        = {Gagan Bhatia and Maxime Peyrard and Wei Zhao},
Title         = {Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning},
Journal       = {2505.16088v3},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Modern BPE tokenizers often split calendar dates into meaningless fragments, e.g., 20250312 $\rightarrow$ 202, 503, 12, inflating token counts and obscuring the inherent structure needed for robust temporal reasoning. In this work, we (1) introduce a simple yet interpretable metric, termed date fragmentation ratio, that measures how faithfully a tokenizer preserves multi-digit date components; (2) release DateAugBench, a suite of 6500 examples spanning three temporal reasoning tasks: context-based date resolution, format-invariance puzzles, and date arithmetic across historical, contemporary, and future time periods; and (3) through layer-wise probing and causal attention-hop analyses, uncover an emergent date-abstraction mechanism whereby large language models stitch together the fragments of month, day, and year components for temporal reasoning. Our experiments show that excessive fragmentation correlates with accuracy drops of up to 10 points on uncommon dates like historical and futuristic dates. Further, we find that the larger the model, the faster the emergent date abstraction that heals date fragments is accomplished. Lastly, we observe a reasoning path that LLMs follow to assemble date fragments, typically differing from human interpretation (year $\rightarrow$ month $\rightarrow$ day). Our datasets and code are made publicly available \href{https://github.com/gagan3012/date-fragments}{here}.},
Year          = {2025},
Month         = {May},
Url           = {http://arxiv.org/abs/2505.16088v3},
File          = {2505.16088v3.pdf}
}"
"@article{bhatia2024datelogicqa,
Author        = {Gagan Bhatia and MingZe Tang and Cristina Mahanta and Madiha Kazi},
Title         = {DateLogicQA: Benchmarking Temporal Biases in Large Language Models},
Journal       = {2412.13377v2},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {This paper introduces DateLogicQA, a benchmark with 190 questions covering diverse date formats, temporal contexts, and reasoning types. We propose the Semantic Integrity Metric to assess tokenization quality and analyse two biases: Representation-Level Bias, affecting embeddings, and Logical-Level Bias, influencing reasoning outputs. Our findings provide a comprehensive evaluation of LLMs' capabilities and limitations in temporal reasoning, highlighting key challenges in handling temporal data accurately.},
Year          = {2024},
Month         = {Dec},
Url           = {http://arxiv.org/abs/2412.13377v2},
File          = {2412.13377v2.pdf}
}"
"@article{bhatia2025distributional,
Author        = {Gagan Bhatia and Somayajulu G Sripada and Kevin Allan and Jacobo Azcona},
Title         = {Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models},
Journal       = {2510.06107v2},
ArchivePrefix = {arXiv},
PrimaryClass  = {cs.CL},
Abstract      = {Large Language Models (LLMs) are prone to hallucination, the generation of plausible yet factually incorrect statements. This work investigates the intrinsic, architectural origins of this failure mode through three primary contributions. First, to enable the reliable tracing of internal semantic failures, we propose Distributional Semantics Tracing (DST), a unified framework that integrates established interpretability techniques to produce a causal map of a model's reasoning, treating meaning as a function of context (distributional semantics). Second, we pinpoint the model's layer at which a hallucination becomes inevitable, identifying a specific commitment layer where a model's internal representations irreversibly diverge from factuality. Third, we identify the underlying mechanism for these failures. We observe a conflict between distinct computational pathways, which we interpret using the lens of dual-process theory: a fast, heuristic associative pathway (akin to System 1) and a slow, deliberate, contextual pathway (akin to System 2), leading to predictable failure modes such as Reasoning Shortcut Hijacks. Our framework's ability to quantify the coherence of the contextual pathway reveals a strong negative correlation ($œÅ= -0.863$) with hallucination rates, implying that these failures are predictable consequences of internal semantic weakness. The result is a mechanistic account of how, when, and why hallucinations occur within the Transformer architecture.},
Year          = {2025},
Month         = {Oct},
Url           = {http://arxiv.org/abs/2510.06107v2},
File          = {2510.06107v2.pdf}
}"
